{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f51f99-90d8-40dc-8fce-51ee3242f937",
   "metadata": {},
   "source": [
    "### Simple Calculation of attentation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8352d73-6eab-48c7-99d1-9f1df1d4d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89], # Your (x^1)\n",
    "    [0.55, 0.87, 0.66], # journey (x^2)\n",
    "    [0.57, 0.85, 0.64], # starts (x^3)\n",
    "    [0.22, 0.58, 0.33], # with (x^4)\n",
    "    [0.77, 0.25, 0.10], # one (x^5)\n",
    "    [0.05, 0.80, 0.55]] # step (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bc581-89aa-40e4-847e-039834a60476",
   "metadata": {},
   "source": [
    "### Just for `journey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0812421-96f2-4c8f-a0ef-1b2aab4c2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5617)\n",
      "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attention_score = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attention_score[i] = query @ x_i # Dot Product\n",
    "## attention_score sum\n",
    "print(attention_score.sum())\n",
    "## normalize att score\n",
    "attention_score_norm = attention_score/attention_score.sum() # Done to increase training stability, generally done using softmax\n",
    "print(attention_score_norm)\n",
    "## normalize att score sum\n",
    "print(attention_score_norm.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823d0915-049b-4aba-9c90-5539a844b92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "# better norm to handle extreme values, and ensure weights are +ve\n",
    "atte_score_norm  = softmax_naive(attention_score) \n",
    "atte_score_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a20c37-d953-41fd-bea4-a55e42ca135a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6515, 0.5683])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context vector\n",
    "context_vector = torch.empty(inputs.shape[1])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vector += atte_score_norm[i] * x_i # Multiply the atten score for that input with input and sum them together\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16a867-f3de-476f-bdb5-34f06b083de4",
   "metadata": {},
   "source": [
    "### Atten and Context Calculation for everything naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71b5ca3-731b-46f2-b99e-97244893b14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6515, 0.5683])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## norm att\n",
    "att = torch.empty((inputs.shape[0], inputs.shape[0]))\n",
    "for idx, query in enumerate(inputs):\n",
    "    for i, x_i in enumerate(inputs):\n",
    "        att[idx][i] = query @ x_i\n",
    "att_norm = torch.softmax(att, dim=1) # torch softmax bro\n",
    "# context vector\n",
    "context = torch.empty(inputs.shape)\n",
    "for idx, a_n in enumerate(att_norm):\n",
    "    for i, x_i in enumerate(inputs):\n",
    "        context[idx] += a_n[i] * x_i\n",
    "context[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf026b8-db7d-4d32-b859-2e23f097edb7",
   "metadata": {},
   "source": [
    "### Atten and Context Calculation for everything matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ee1b68-4fab-46e0-aae4-14c937a4bbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6515, 0.5683])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = inputs @ inputs.T\n",
    "att_norm = torch.softmax(att, dim=1) # torch softmax bro\n",
    "context = att_norm @ inputs\n",
    "context[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8ae92-05e5-4e4a-9b04-7b0ae3ed12cd",
   "metadata": {},
   "source": [
    "### Adding trainable parameters to the self-attentation\n",
    "\n",
    ">from the book:\n",
    ">\n",
    ">**Weight parameters vs. attention weights**\n",
    ">\n",
    ">In the weight matrices W, the term “weight” is short for “weight parameters,” the val-\n",
    "ues of a neural network that are optimized during training. This is not to be confused\n",
    "with the attention weights. As we already saw, attention weights determine the extent\n",
    "to which a context vector depends on the different parts of the input (i.e., to what\n",
    "extent the network focuses on different parts of the input).\n",
    "In summary, weight parameters are the fundamental, learned coefficients that define\n",
    "the network’s connections, while attention weights are dynamic, context-specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a307118a-9afd-4f55-a107-8f0bfb30394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1] # 3\n",
    "d_out = 2\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "query_2 = x_2 @ W_query\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d88221e-83e7-47cf-a251-dd4ed57c90ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8524)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = inputs @ W_key\n",
    "value = inputs @ W_value\n",
    "\n",
    "# We need to compute the att_score for journey with just key[1]\n",
    "att_score_22 = query_2 @ key[1] \n",
    "att_score_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea83a46-012a-41d4-a00a-6073608e9f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3061, 0.8210])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting actual att score for `journey`\n",
    "att_score_2 = query_2 @ key.T\n",
    "# Scaling the att\n",
    "d_k = key.shape[-1]\n",
    "attn_weights_2 = torch.softmax(att_score_2 / d_k**0.5, dim=-1)\n",
    "context_vec2 = attn_weights_2 @ value\n",
    "context_vec2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
